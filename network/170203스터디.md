#블록 디바이스와 관련 개념들

##Contents

1. block

2. block device

3. page

4. page frame

5. page table

6. page table entry

7. paging

8. segments

9. virtual memory

10. physical memory

11. mmu

12. TLB

13. LRU

14. file system

###block
블록은 입출력 장치(주로 기억장치)와 효율적으로 통신하기 위한 가장 작은 단위이다.  
실제로는 비트나 바이트가 순차적으로 나열된 형태로 구현되어 있다.  
이렇게 블록단위로 구조화된 데이터를 블록된 데이터(blocked data)라고 한다.  


블로킹은 블록에 데이터를 저장하는 과정을 말한다.  
디블로킹은 블록에서 데이터를 추출하는 과정을 말한다.  


블럭된 데이터는 보통 데이터 버퍼에 저장된다. 그리고 하나의 블록 전체가 한번에 읽거나 쓰게된다.  
따라서 블로킹은 오버헤드를 줄이고 데이터 스트림의 처리 속도를 높인다.  
파일 크기가 블록크기의 정수배를 이룬다면 가장 이상적으로 하드웨어를 사용할 수 있지만,  
아닌 경우가 있기 때문에 내부적으로 디스크 단편화가 생기고 이로 인해서 공간 비효율이 생긴다.  


또한 블럭크기는 대체로 512바이트이거나 그 정수배를 취하는데, 이는 역사적인 이유에 기인한다.  
전통적으로 HDD의 Disk Sector(하드 디스크가 다루는 가장 작은 단위)가 512바이트이기 때문이다.  
여기에 더해 대부분의 파일 시스템은 블록 디바이스(블록 단위로 입출력하는 *주로* 기억장치)를 기반으로 구현되어 있다.  


###block device
유닉스 계열 운영 체제에서 장치 파일이나 특수 파일은 마치 일반 파일인 것처럼 파일 시스템에 표현되는 장치 드라이버의 인터페이스다.
그 중에서도 눈에 띄는 것이 블록 디바이스 파일이다.  
블록 특수 파일이나 블록 디바이스는 하드웨어 장치에 대한 버퍼링된 접근을 제공하고 세부적인 사항을 추상화 한다.
문자 장치와 달리 블록 디바이스는 항상 프로그래머가 모든 크기의 블록 (단일 문자 / 바이트 포함) 및 정렬을 읽거나 쓸 수 있다.


자세한 사항은 버퍼 입출력에 대해서 공부하면 더 많은 것을 알 수 있게 될 것이다.  
###page
페이지, 메모리 페이지, 가상 페이지는 1개의 페이지 테이블 엔트리로 볼 수 있는  
가상 메모리의 고정된 길이의 연속된 블록이다.  
가상 메모리를 사용하는 운영체제에서 메모리를 관리하기 위한 최소 단위이기도 하다.  
주 메모리와 하드 디스크 드라이브와 같은 보조 저장소 사이의 페이지 이동, 전송 등 페이지를 관리하는 기법 또는 행위를 페이징 또는 스와핑이라고 한다.  
###page frame
페이지 프레임은 메모리 페이지가 운영 체제에 의해 매핑되는 물리적 메모리의 가장 작은 고정된 길이의 연속된 블록들을 뜻한다.  

###page table
페이지 테이블은 가상 주소와 실제 주소 사이의 매핑을 저장하기 위해 컴퓨터 운영 체제의 가상 메모리 시스템에서 사용하는 데이터 구조다.  
가상 주소는 운영 체제와 그 구성 요소에서 사용하는 반면, 물리적 주소는 하드웨어 또는 RAM 서브 시스템에 의해 사용한다.  

###page table entry
프로세스가 메모리의 데이터에 대한 액세스를 요구할 때,  
프로세스가 제공 한 가상 주소를 해당 데이터가 저장된 실제 메모리의 실제 주소에 매핑하는 것은 운영 체제의 책임이다.  
페이지 테이블은 운영 체제가 가상 주소의 매핑을 실제 주소에 저장하는 곳으로 각 매핑은 페이지 테이블 항목 (PTE)이라고 한다.  

####paging
페이징 기법(paging)은 컴퓨터가 메인 메모리에서 사용하기 위해 2차 기억 장치로부터 데이터를 저장하고 검색하는 메모리 관리 기법이다.   
즉, 가상기억장치를 모두 같은 크기의 블록으로 편성하여 운용하는 기법이다. 이때의 일정한 크기를 가진 블록을 페이지(page)라고 한다.    
주소공간을 페이지 단위로 나누고 실제기억공간은 페이지 크기와 같은 프레임으로 나누어 사용한다.  
페이징 기법이 적용된 시스템에서 가상주소는 순서쌍 (p,d)로 나타낼 수 있다.  
p는 가상기억장치 내에서 참조될 항목이 속해 있는 페이지 번호이고, d는 페이지 p내에서 참조될 항목이 위치하고 있는 곳의 변위이다.  

###segments
세그먼트란 컴퓨터의 primary memory를 세그먼트 또는 섹션이라는 논리적인 단위로 나누는 것이다.  
세그멘테이션을 사용하는 시스템에서, 메모리 위치에 대한 메모리 참조는 세그먼트 및 그 세그먼트 내의 오프셋(메모리 위치)를 식별하는 값을 포함한다.  
세그먼트는 바이트 단위로 그 크기를 정의하기도 하고 페이지와 함께 구현되어 페이지 단위로 관리될 수도 있다.  
또한 고정되어 있지 않은 크기를 가지기에, 어떤 세그먼트인지에 따라서  굉장히 작은 크기를 가질수도 있고, 반대로 굉장히 큰 크기를 가질 수도 있다.  
(물론 각 세그먼트의 크기는 같지 않다.)  


세그먼트와 페이지의 차이점은 상당히 큰데 이점은 아래에서 따로 설명하겠다.  
####data segments
컴퓨팅에서 데이터 세그먼트 (.data라고도 함)는 개체 파일의 일부이거나 초기화 된 정적 변수, 즉 전역 변수와 정적 로컬 변수가 들어있는 프로그램의 해당 가상 주소 공간이다.  
이 세그먼트의 크기는 프로그램의 소스 코드에있는 값의 크기에 의해 결정되며 런타임에 변경되지 않습니다.  
변수의 값은 런타임에 변경 될 수 있기 때문에 데이터 세그먼트는 읽기-쓰기가 가능하다.  
이것은 변수가 아닌 정적 상수를 포함하는 읽기 전용 데이터 세그먼트와는 대조적이다.  
또한 많은 아키텍처에서 읽기 전용인 코드 세그먼트 (텍스트 세그먼트라고도 함)와 대조된다. 초기화되지 않은 데이터 (변수와 상수 모두)는 대신 BSS 세그먼트에 있습니다.  
####code segments
컴퓨팅에서 코드 세그먼트는 텍스트 세그먼트 또는 단순히 텍스트라고도하며 실행 파일 명령이 들어있는 프로그램의 가상 주소 공간에서 해당 파일 또는 개체 파일의 일부분이다.  
"세그먼트"라는 용어는 페이징에 의해 성공한 메모리 관리에 대한 역사적인 접근 방식인 메모리 세그먼트에서 비롯된 것이다.  
프로그램이 오브젝트 파일에 저장되면 코드 세그먼트는이 파일의 일부입니다.  
로더가 프로그램을 메모리에 저장하여 실행될 때, 오브젝트 파일의 두 세그먼트와 런타임에만 필요한 세그먼트에 해당하는 다양한 메모리 영역 (특히 페이지)이 할당됩니다.  
예를 들어, 오브젝트 파일의 코드 세그먼트는 메모리의 해당 코드 세그먼트에 로드된다.    


메모리의 코드 세그먼트는 일반적으로 읽기 전용이며 고정 크기이므로 임베디드 시스템에서는 일반적으로로드 할 필요없이 읽기 전용 메모리 (ROM)에 배치 할 수 있습니다.  
코드 세그먼트가 읽기 전용이 아니면 특정 아키텍처가 자체 수정 코드를 허용합니다.  
고정 된 위치 또는 위치 독립적 인 코드는 분할 또는 페이지 메모리 시스템에서 여러 프로세스에 의해 메모리에서 공유 될 수 있습니다.  
메모리 영역으로서 힙 및 스택 오버 플로우가 겹쳐 쓰기를 방지하기 위해 코드 세그먼트를 힙 또는 스택 아래에 배치 할 수 있습니다.  
###virtual memory
가상 메모리(문화어: 가상기억기) 또는 가상 기억 장치는 RAM을 관리하는 방법의 하나로, 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식을 말한다.  
이러한 방식은 멀티태스킹 운영 체제에서 흔히 사용되며, 실제 주기억장치보다 큰 메모리 영역을 제공하는 방법으로도 사용된다.  
가상적으로 주어진 주소를 가상 주소(virtual address) 또는 논리 주소(logical address) 라고 하며,  
실제 메모리 상에서 유효한 주소를 물리 주소(physical address) 또는 실주소(real address)라고 한다. 가상 주소의 범위를 가상 주소 공간, 물리 주소의 범위를 물리 주소 공간이라고 한다.  
가상 주소 공간은 메모리 관리 장치(MMU)에 의해서 물리 주소로 변환된다.   


이 덕분에 프로그래머는 가상 주소 공간상에서 프로그램을 짜게 되어 프로그램이나 데이터가 주메모리상에 어떻게 존재하는지를 의식할 필요가 없어진다. 
대부분의 현대적 아키텍처와 운영 체제는 가상 메모리 기능을 제공하며,  
각 응용 프로그램에 더 적합한 메모리 관리를 위해 어도비 포토샵과 같은 일부 응용 프로그램은 스스로 가상 메모리를 관리하기도 한다.  


가상 메모리의 주요 이점으로는 응용 프로그램이 공유 메모리 공간을 관리하지 않아도 되고, 메모리를 격리시켜 보안이 강화되며, 
물리적으로 사용할 수있는 것보다 많은 메모리를 페이징 기술을 사용하여 개념적으로 사용할 수 있다는 것이다.
###mmu
PMMU(paged Memory management unit)이라고도 불리는 메모리 관리 장치(Memory Management Unit, 줄여서 MMU)는 CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어 부품이다.  
가상 메모리 주소를 실제 메모리 주소로 변환하며, 메모리 보호, 캐시 관리, 버스 중재 등의 역할을 담당하며 간단한 8비트 아키텍처에서는 뱅크 스위칭을 담당하기도 한다.  


참고로 뱅크 스위치가 뜻하는 바는 다음과 같다.  
뱅크 전환(bank switching)은 마이크로프로세서의 주소 공간보다 많은 메모리를 활용하기 위해 개발된 기술이다.  
주로 8비트 마이크로프로세서에서 사용되었으며, 거의 대부분의 8비트 마이크로프로세서가 16비트 주소 공간이므로 216 = 65536 매모리 공간을 갖는다. 
이것보다 많은 메모리를 확장하려면 뱅크스위칭을 사용한다. 그러나 주소공간 내에서 액세스가 되어야 하므로 동시에 64 kB보다 많은 공간을 식별할 수 없다. 
따라서 사용하는 뱅크를 설정하고 해당공간만을 액세스하다가, 뱅크를 바꾸어 다른 공간을 활용한다.  
같은 주소공간의 뱅크를 스위칭하는 방법은 논리회로의 주소 디코더에 의한 설정에 의해 결정된다.  
같은 주소공간의 여러개의 뱅크 중에 선택된 뱅크만이 액세스 되도록 하고 선택되지 않은 뱅크는 데이터를 유지만 하도록 동작 한다  


최신 아키텍처에서 MMU는 가상 주소공간을 2N비트 크기의 페이지들로 나눈다. 그 가운데 일부 페이지는 실제 메모리 주소의 한 페이지에 대응되는데,  
대부분의 경우 가상 주소공간은 실제 메모리의 주소공간보다 크기 때문에 모든 페이지가 실제 메모리에 대응되는 것은 아니다.  
CPU가 가상 메모리 주소를 MMU에 넘겨주면 MMU는 그 주소를 받아 뒤쪽의 N비트는 바꾸지 않고 앞쪽의 나머지 비트를 그에 해당하는 실제 메모리 주소로 바꾼다.  
이때 가상 메모리 주소와 실제 메모리 주소 사이의 변환을 위해 MMU는 변환 참조 버퍼(Translation Lookaside Buffer, TLB)라는 고속의 보조기억장치를 참조한다.  
이 보조기억장치에 원하는 변환 정보가 없을 때는 더 느린 다른 방법으로 페이지 변환 정보를 얻어오는데, 이 페이지 변환 정보가 담겨 있는 자료구조를 페이지 테이블(Page Table)이라 한다.  
페이지 테이블의 동작은 아키텍처와 운영체제에 따라 서로 다르다.  
###TLB
변환 색인 버퍼(Translation Lookaside Buffer, TLB)는 가상 메모리 주소를 물리적인 주소로 변환하는 속도를 높이기 위해 사용되는 캐시로, 약칭은 TLB이다.  
TLB는 최근에 일어난 가상 메모리 주소와 물리 주소의 변환 테이블을 저장하기 때문에 일종의 주소 변환 캐시라고 할 수 있다.  
TLB는 CPU와 CPU 캐시 사이, CPU 캐시와 메인 메모리 사이 등 여러가지 다른 레벨의 캐시들 사이에서 주소를 변환하는데 사용할 수 있다.  
현재 모든 데스크탑 및 서버용 프로세서는 하나 또는 그 이상의 TLB를 메모리 관리 하드웨어에 가지고 있다.  
페이지 단위나 세그먼트 단위로 처리하는 가상 메모리를 사용하는 거의 모든 하드웨어는 TLB를 사용한다.  
CPU는 1차적으로 TLB에 접근하여 원하는 페이지가 존재하는지 탐색하고, TLB에 존재하지 않을 경우 MMU의 페이지 테이블을 참조한다.  

###LRU
가장 최근에 사용 된 (LRU) 페이지 교체 알고리즘은 NRU와 이름이 유사하지만 LRU가 짧은 시간 동안 페이지 사용량을 추적한다는 점에서 다르며 NRU는 마지막 클럭 간격에서 사용량을 확인한다.  
LRU는 지난 몇 가지 지침에서 가장 많이 사용 된 페이지가 다음 몇 가지 지침에서도 많이 사용될 것 같다고 생각합니다.  
LRU가 이론상으로 거의 최적의 성능을 제공 할 수 있지만 (실제로는 적응 형 대체 캐시만큼 좋음) 실제로 구현하는 데 비용이 많이 듭니다.  
가능한 한 많은 성능을 유지하면서 비용을 줄이려고 시도하는이 알고리즘에는 몇 가지 구현 방법이 있습니다.  

###file system
일단 넘어간다.  


###부록 - segments VS page
	* 페이지  : 고정적이고 물리적인 단위이다. + 부가적인 기능을 제공하지 않는다. 
	* 또한 페이지는 프로그래머에게 투명한, 명료한(transparent) 특징을 가지고 있다.
	* 세그먼트: 논리적이고 가변적이다. + 부가적인 기능으로 독립적인 주소공간을 사용할 수 있게 되고, 외부로 부터의 오염을 방지하는 기능도 제공한다.  
	* 세그먼트는 프로그래머에게 visible(가시적, 파악하기 쉬운) 특징을 가지고 있다.
	* 두 개념은 조합적으로 구현되고 사용할 수 있는 개념이며 현대의 운영체제는 대부분 이렇게 구현된다.



* 출처:


	* https://en.wikipedia.org/wiki/Page_table
	* https://en.wikipedia.org/wiki/Page_(computer_memory)
	* https://en.wikipedia.org/wiki/Data_segment
	* https://en.wikipedia.org/wiki/Code_segment
	* https://en.wikipedia.org/wiki/Memory_segmentation
	* https://en.wikipedia.org/wiki/Virtual_memory
	* https://en.wikipedia.org/wiki/Memory_management_unit
	* https://en.wikipedia.org/wiki/Translation_lookaside_buffer
	* https://en.wikipedia.org/wiki/Page_replacement_algorithm
	* 또는 이 웹페이지의 한국어 버전이 있다면 그 또한 참고했습니다.


	* http://www.slideshare.net/Tech_MX/combined-paging-and-segmentation
